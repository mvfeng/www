
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="0_Simple__simpleP2P.cu解析">
      
      
        <meta name="author" content="mvfeng">
      
      
        <link rel="canonical" href="https://www.94c.cn/cuda/0_Simple__simpleP2P.cu%E8%A7%A3%E6%9E%90/">
      
      
      
        <link rel="next" href="../../ai/deepseek/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.11">
    
    
      
        <title>0_Simple__simpleP2P.cu解析 - 94C官网</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4af4bdda.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.css">
    
      <link rel="stylesheet" href="../../mkdocs/css/no-footer.css">
    
      <link rel="stylesheet" href="../../mkdocs/css/unordered-list-symbols.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../.." title="94C官网" class="md-header__button md-logo" aria-label="94C官网" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            94C官网
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              0_Simple__simpleP2P.cu解析
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="切换至夜间模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换至夜间模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="切换至日间模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换至日间模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/mvfeng/www_edit.git" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    www_edit
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="./" class="md-tabs__link">
          
  
  
    
  
  AI专题

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../pcie3.0_mindshare/18_SystemReset%E7%B3%BB%E7%BB%9F%E5%A4%8D%E4%BD%8D/" class="md-tabs__link">
          
  
  
    
  
  PCIe

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../linux/operation/nmcli%E9%85%8D%E7%BD%AEip/" class="md-tabs__link">
          
  
  
    
  
  Linux运维

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="94C官网" class="md-nav__button md-logo" aria-label="94C官网" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    94C官网
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mvfeng/www_edit.git" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    www_edit
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    AI专题
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            AI专题
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_1" checked>
        
          
          <label class="md-nav__link" for="__nav_1_1" id="__nav_1_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    cuda
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1_1">
            <span class="md-nav__icon md-icon"></span>
            cuda
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    0_Simple__simpleP2P.cu解析
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    0_Simple__simpleP2P.cu解析
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 源代码
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 重要点
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 重要点">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#p2p" class="md-nav__link">
    <span class="md-ellipsis">
      使用P2P的关键步骤
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_2" >
        
          
          <label class="md-nav__link" for="__nav_1_2" id="__nav_1_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    deepseek
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_2">
            <span class="md-nav__icon md-icon"></span>
            deepseek
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ai/deepseek/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4090单卡运行Deepseek r1:671B满血版
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    PCIe
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            PCIe
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    pcie3.0_mindshare
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            pcie3.0_mindshare
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pcie3.0_mindshare/18_SystemReset%E7%B3%BB%E7%BB%9F%E5%A4%8D%E4%BD%8D/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    18_SystemReset系统复位
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Linux运维
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Linux运维
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    常见问题
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            常见问题
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/operation/nmcli%E9%85%8D%E7%BD%AEip/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    nmcli配置ip
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/operation/bmc%E5%B8%B8%E7%94%A8ipmitool%E6%8C%87%E4%BB%A4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    bmc常用ipmitool指令
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/operation/linux%E5%B8%B8%E7%94%A8%E6%BA%90/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Linux常用源
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/operation/RedHat%E7%B3%BB%E5%88%97%E6%8D%A2%E6%BA%90/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RedHat系列换源
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/operation/iperf3%E7%9B%B8%E4%BA%92%E6%89%93%E6%B5%81/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    iperf3相互打流
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/operation/centos8%E5%BF%98%E8%AE%B0%E5%AF%86%E7%A0%81%E5%A6%82%E4%BD%95%E9%87%8D%E7%BD%AE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Centos8忘记密码如何重置
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/operation/python%E5%85%A8%E5%AE%89%E8%A3%85/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python全安装
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/operation/raid%E5%8D%A1os%E5%91%BD%E4%BB%A4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Raid卡os命令
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    docker
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            docker
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../linux/docker/docker%E6%BA%90/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    docker或dockerhub的国内镜像源或加速列表4月15日更新长期维护
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 源代码
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 重要点
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 重要点">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#p2p" class="md-nav__link">
    <span class="md-ellipsis">
      使用P2P的关键步骤
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/mvfeng/www_edit.git/edit/main/docs/cuda/0_Simple__simpleP2P.cu解析.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  


  <h1>0_Simple__simpleP2P.cu解析</h1>

<ul>
<li>"cuda"</li>
<li>"simple"</li>
<li>"simplep2p"</li>
<li>"nvidia"</li>
</ul>
<p><code>simpleP2P.cu</code> 使用 P2P 特性在 GPU 之间传输、读写数据。
源代码。包括 P2P 使用前的各项检查，设备之间的数据互拷，主机和设备之间数据传输和相互访问。</p>
<p>以下是使用 <code>ipmitool</code> 配置 BMC 的一些常见操作：</p>
<p><strong>注意</strong>：<a href="https://github.com/NVIDIA/cuda-samples/blob/master/Samples/0_Introduction/simpleP2P/simpleP2P.cu">github上simpleP2P源代码</a></p>
<h3 id="1">1. 源代码<a class="headerlink" href="#1" title="Permanent link">&para;</a></h3>
<div class="language-bash highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Bash</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  1</span>
<span class="normal">  2</span>
<span class="normal">  3</span>
<span class="normal">  4</span>
<span class="normal">  5</span>
<span class="normal">  6</span>
<span class="normal">  7</span>
<span class="normal">  8</span>
<span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-1"><span class="c1">#include &lt;stdlib.h&gt;</span>
</span><span id="__span-0-2"><span class="c1">#include &lt;stdio.h&gt;</span>
</span><span id="__span-0-3"><span class="c1">#include &lt;cuda_runtime.h&gt;</span>
</span><span id="__span-0-4"><span class="c1">#include &quot;device_launch_parameters.h&quot;</span>
</span><span id="__span-0-5"><span class="c1">#include &lt;helper_cuda.h&gt;</span>
</span><span id="__span-0-6"><span class="c1">#include &lt;helper_functions.h&gt;</span>
</span><span id="__span-0-7">
</span><span id="__span-0-8"><span class="c1">#define MAX_GPU_COUNT 64</span>
</span><span id="__span-0-9">
</span><span id="__span-0-10">__global__<span class="w"> </span>void<span class="w"> </span>SimpleKernel<span class="o">(</span>float<span class="w"> </span>*src,<span class="w"> </span>float<span class="w"> </span>*dst<span class="o">)</span>
</span><span id="__span-0-11"><span class="o">{</span>
</span><span id="__span-0-12"><span class="w">    </span>const<span class="w"> </span>int<span class="w"> </span><span class="nv">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>blockIdx.x<span class="w"> </span>*<span class="w"> </span>blockDim.x<span class="w"> </span>+<span class="w"> </span>threadIdx.x<span class="p">;</span>
</span><span id="__span-0-13"><span class="w">    </span>dst<span class="o">[</span>idx<span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>src<span class="o">[</span>idx<span class="o">]</span><span class="w"> </span>*<span class="w"> </span><span class="m">2</span>.0f<span class="p">;</span>
</span><span id="__span-0-14"><span class="o">}</span>
</span><span id="__span-0-15">
</span><span id="__span-0-16">inline<span class="w"> </span>bool<span class="w"> </span>IsGPUCapableP2P<span class="o">(</span>cudaDeviceProp<span class="w"> </span>*pProp<span class="o">)</span>
</span><span id="__span-0-17"><span class="o">{</span>
</span><span id="__span-0-18"><span class="c1">#ifdef _WIN32</span>
</span><span id="__span-0-19"><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">(</span>bool<span class="o">)(</span>pProp-&gt;tccDriver<span class="w"> </span>?<span class="w"> </span><span class="nb">true</span><span class="w"> </span>:<span class="w"> </span><span class="nb">false</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-20"><span class="c1">#else</span>
</span><span id="__span-0-21"><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="o">(</span>bool<span class="o">)(</span>pProp-&gt;major<span class="w"> </span>&gt;<span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-22"><span class="c1">#endif</span>
</span><span id="__span-0-23"><span class="o">}</span>
</span><span id="__span-0-24">
</span><span id="__span-0-25">int<span class="w"> </span>main<span class="o">(</span>int<span class="w"> </span>argc,<span class="w"> </span>char<span class="w"> </span>**argv<span class="o">)</span>
</span><span id="__span-0-26"><span class="o">{</span>
</span><span id="__span-0-27"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\tStarting\n&quot;</span>,<span class="w"> </span>argv<span class="o">[</span><span class="m">0</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-28">
</span><span id="__span-0-29"><span class="w">    </span>//<span class="w"> </span>检查是否使用<span class="w"> </span><span class="m">64</span><span class="w"> </span>位操作系统环境
</span><span id="__span-0-30"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>sizeof<span class="o">(</span>void*<span class="o">)</span><span class="w"> </span>!<span class="o">=</span><span class="w"> </span><span class="m">8</span><span class="o">)</span>
</span><span id="__span-0-31"><span class="w">    </span><span class="o">{</span>
</span><span id="__span-0-32"><span class="w">        </span>printf<span class="o">(</span><span class="s2">&quot;\n\tError for program only supported with 64-bit OS and 64-bit target\n&quot;</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-33"><span class="w">        </span><span class="k">return</span><span class="w"> </span>EXIT_WAIVED<span class="p">;</span>
</span><span id="__span-0-34"><span class="w">    </span><span class="o">}</span>
</span><span id="__span-0-35">
</span><span id="__span-0-36"><span class="w">    </span>//<span class="w"> </span>找到头两块计算能力不小于<span class="w"> </span><span class="m">2</span>.0<span class="w"> </span>的设备
</span><span id="__span-0-37"><span class="w">    </span>int<span class="w"> </span>gpu_n<span class="p">;</span>
</span><span id="__span-0-38"><span class="w">    </span>cudaGetDeviceCount<span class="o">(</span><span class="p">&amp;</span>gpu_n<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-39"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\tDevice count: %d\n&quot;</span>,<span class="w"> </span>gpu_n<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-40"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>gpu_n<span class="w"> </span>&lt;<span class="w"> </span><span class="m">2</span><span class="o">)</span>
</span><span id="__span-0-41"><span class="w">    </span><span class="o">{</span>
</span><span id="__span-0-42"><span class="w">        </span>printf<span class="o">(</span><span class="s2">&quot;\n\tError for two or more GPUs with SM2.0 required\n&quot;</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-43"><span class="w">        </span><span class="k">return</span><span class="w"> </span>EXIT_WAIVED<span class="p">;</span>
</span><span id="__span-0-44"><span class="w">    </span><span class="o">}</span>
</span><span id="__span-0-45">
</span><span id="__span-0-46"><span class="w">    </span>cudaDeviceProp<span class="w"> </span>prop<span class="o">[</span>MAX_GPU_COUNT<span class="o">]</span><span class="p">;</span>
</span><span id="__span-0-47"><span class="w">    </span>int<span class="w"> </span>gpuid<span class="o">[</span>MAX_GPU_COUNT<span class="o">]</span>,<span class="w"> </span><span class="nv">gpu_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">;</span>
</span><span id="__span-0-48"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\tShow device\n&quot;</span><span class="o">)</span><span class="p">;</span>//<span class="w"> </span>展示所有设备
</span><span id="__span-0-49"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="o">(</span>int<span class="w"> </span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i<span class="w"> </span>&lt;<span class="w"> </span>gpu_n<span class="p">;</span><span class="w"> </span>i++<span class="o">)</span>
</span><span id="__span-0-50"><span class="w">    </span><span class="o">{</span>
</span><span id="__span-0-51"><span class="w">        </span>cudaGetDeviceProperties<span class="o">(</span><span class="p">&amp;</span>prop<span class="o">[</span>i<span class="o">]</span>,<span class="w"> </span>i<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-52"><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="o">((</span>prop<span class="o">[</span>i<span class="o">]</span>.major<span class="w"> </span>&gt;<span class="o">=</span><span class="w"> </span><span class="m">2</span><span class="o">)</span>
</span><span id="__span-0-53"><span class="c1">#ifdef _WIN32</span>
</span><span id="__span-0-54"><span class="w">            </span><span class="o">&amp;&amp;</span><span class="w"> </span>prop<span class="o">[</span>i<span class="o">]</span>.tccDriver//<span class="w"> </span>Windows<span class="w"> </span>系统还要求有<span class="w"> </span>Tesla<span class="w"> </span>计算集群驱动
</span><span id="__span-0-55"><span class="c1">#endif</span>
</span><span id="__span-0-56"><span class="w">           </span><span class="o">)</span>
</span><span id="__span-0-57"><span class="w">            </span>gpuid<span class="o">[</span>gpu_count++<span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>i<span class="p">;</span>
</span><span id="__span-0-58"><span class="w">        </span>printf<span class="o">(</span><span class="s2">&quot;\n\tGPU%d = \&quot;%15s\&quot; ---- %s\n&quot;</span>,<span class="w"> </span>i,<span class="w"> </span>prop<span class="o">[</span>i<span class="o">]</span>.name,<span class="w"> </span><span class="o">(</span>IsGPUCapableP2P<span class="o">(</span><span class="p">&amp;</span>prop<span class="o">[</span>i<span class="o">])</span><span class="w"> </span>?<span class="w"> </span><span class="s2">&quot;YES&quot;</span><span class="w"> </span>:<span class="w"> </span><span class="s2">&quot;NO&quot;</span><span class="o">))</span><span class="p">;</span>
</span><span id="__span-0-59"><span class="w">    </span><span class="o">}</span>
</span><span id="__span-0-60"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>gpu_count<span class="w"> </span>&lt;<span class="w"> </span><span class="m">2</span><span class="o">)</span>
</span><span id="__span-0-61"><span class="w">    </span><span class="o">{</span>
</span><span id="__span-0-62"><span class="w">        </span>printf<span class="o">(</span><span class="s2">&quot;\n\tError for two or more GPUs with SM2.0 required\n&quot;</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-63"><span class="c1">#ifdef _WIN32</span>
</span><span id="__span-0-64"><span class="w">        </span>printf<span class="o">(</span><span class="s2">&quot;\nOr for TCC driver required\n&quot;</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-65"><span class="c1">#endif</span>
</span><span id="__span-0-66"><span class="w">        </span>cudaSetDevice<span class="o">(</span><span class="m">0</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-67"><span class="w">        </span><span class="k">return</span><span class="w"> </span>EXIT_WAIVED<span class="p">;</span>
</span><span id="__span-0-68"><span class="w">    </span><span class="o">}</span>
</span><span id="__span-0-69">
</span><span id="__span-0-70"><span class="w">    </span>//<span class="w"> </span>寻找测试设备
</span><span id="__span-0-71"><span class="w">    </span>int<span class="w"> </span>can_access_peer,<span class="w"> </span>p2pCapableGPUs<span class="o">[</span><span class="m">2</span><span class="o">]</span><span class="p">;</span>
</span><span id="__span-0-72"><span class="w">    </span>p2pCapableGPUs<span class="o">[</span><span class="m">0</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>p2pCapableGPUs<span class="o">[</span><span class="m">1</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>-1<span class="p">;</span>
</span><span id="__span-0-73"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\tShow combination of devices with P2P\n&quot;</span><span class="o">)</span><span class="p">;</span>//<span class="w"> </span>展示所有能<span class="w"> </span>P2P<span class="w"> </span>的设备组合
</span><span id="__span-0-74"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="o">(</span>int<span class="w"> </span><span class="nv">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i<span class="w"> </span>&lt;<span class="w"> </span>gpu_count<span class="w"> </span>-<span class="w"> </span><span class="m">1</span><span class="p">;</span><span class="w"> </span>i++<span class="o">)</span>
</span><span id="__span-0-75"><span class="w">    </span><span class="o">{</span>
</span><span id="__span-0-76"><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="o">(</span>int<span class="w"> </span><span class="nv">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>i<span class="w"> </span>+<span class="w"> </span><span class="m">1</span><span class="p">;</span><span class="w"> </span>j<span class="w"> </span>&lt;<span class="w"> </span>gpu_count<span class="p">;</span><span class="w"> </span>j++<span class="o">)</span>
</span><span id="__span-0-77"><span class="w">        </span><span class="o">{</span>
</span><span id="__span-0-78"><span class="w">            </span>cudaDeviceCanAccessPeer<span class="o">(</span><span class="p">&amp;</span>can_access_peer,<span class="w"> </span>gpuid<span class="o">[</span>i<span class="o">]</span>,<span class="w"> </span>gpuid<span class="o">[</span>j<span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-79"><span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>can_access_peer<span class="o">)</span>
</span><span id="__span-0-80"><span class="w">            </span><span class="o">{</span>
</span><span id="__span-0-81"><span class="w">                </span>printf<span class="o">(</span><span class="s2">&quot;\n\tGPU%d (%s) &lt;--&gt; GPU%d (%s) : %s\n&quot;</span>,<span class="w"> </span>gpuid<span class="o">[</span>i<span class="o">]</span>,<span class="w"> </span>prop<span class="o">[</span>gpuid<span class="o">[</span>i<span class="o">]]</span>.name,<span class="w"> </span>gpuid<span class="o">[</span>j<span class="o">]</span>,<span class="w"> </span>prop<span class="o">[</span>gpuid<span class="o">[</span>j<span class="o">]]</span>.name<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-82"><span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>p2pCapableGPUs<span class="o">[</span><span class="m">0</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span>-1<span class="o">)</span>
</span><span id="__span-0-83"><span class="w">                    </span>p2pCapableGPUs<span class="o">[</span><span class="m">0</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>gpuid<span class="o">[</span>i<span class="o">]</span>,<span class="w"> </span>p2pCapableGPUs<span class="o">[</span><span class="m">1</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>gpuid<span class="o">[</span>j<span class="o">]</span><span class="p">;</span>
</span><span id="__span-0-84"><span class="w">            </span><span class="o">}</span>
</span><span id="__span-0-85"><span class="w">        </span><span class="o">}</span>
</span><span id="__span-0-86"><span class="w">    </span><span class="o">}</span>
</span><span id="__span-0-87"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>p2pCapableGPUs<span class="o">[</span><span class="m">0</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span>-1<span class="w"> </span><span class="o">||</span><span class="w"> </span>p2pCapableGPUs<span class="o">[</span><span class="m">1</span><span class="o">]</span><span class="w"> </span><span class="o">==</span><span class="w"> </span>-1<span class="o">)</span>
</span><span id="__span-0-88"><span class="w">    </span><span class="o">{</span>
</span><span id="__span-0-89"><span class="w">        </span>printf<span class="o">(</span><span class="s2">&quot;\n\tError for P2P not available among GPUs\n&quot;</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-90"><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="o">(</span>int<span class="w"> </span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i<span class="w"> </span>&lt;<span class="w"> </span>gpu_count<span class="p">;</span><span class="w"> </span>i++<span class="o">)</span>
</span><span id="__span-0-91"><span class="w">            </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span>i<span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-92"><span class="w">        </span><span class="k">return</span><span class="w"> </span>EXIT_WAIVED<span class="p">;</span>
</span><span id="__span-0-93"><span class="w">    </span><span class="o">}</span>
</span><span id="__span-0-94">
</span><span id="__span-0-95"><span class="w">    </span>//<span class="w"> </span>使用找到的设备进行测试
</span><span id="__span-0-96"><span class="w">    </span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>p2pCapableGPUs<span class="o">[</span><span class="m">0</span><span class="o">]</span><span class="p">;</span>
</span><span id="__span-0-97"><span class="w">    </span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>p2pCapableGPUs<span class="o">[</span><span class="m">1</span><span class="o">]</span><span class="p">;</span>
</span><span id="__span-0-98"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\tEnabling P2P between GPU%d and GPU%d\n&quot;</span>,<span class="w"> </span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">]</span>,<span class="w"> </span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-99">
</span><span id="__span-0-100"><span class="w">    </span>//<span class="w"> </span>启用<span class="w"> </span>P2P
</span><span id="__span-0-101"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-102"><span class="w">    </span>cudaDeviceEnablePeerAccess<span class="o">(</span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">]</span>,<span class="w"> </span><span class="m">0</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-103"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-104"><span class="w">    </span>cudaDeviceEnablePeerAccess<span class="o">(</span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">]</span>,<span class="w"> </span><span class="m">0</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-105">
</span><span id="__span-0-106"><span class="w">    </span>//<span class="w"> </span>检查设备是否支持同一可视地址空间<span class="w"> </span><span class="o">(</span>Unified<span class="w"> </span>Virtual<span class="w"> </span>Address<span class="w"> </span>Space，UVA<span class="o">)</span>
</span><span id="__span-0-107"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>!<span class="o">(</span>prop<span class="o">[</span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">]]</span>.unifiedAddressing<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>prop<span class="o">[</span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">]]</span>.unifiedAddressing<span class="o">))</span>
</span><span id="__span-0-108"><span class="w">        </span>printf<span class="o">(</span><span class="s2">&quot;\n\tError for GPU not support UVA\n&quot;</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-109"><span class="w">        </span><span class="k">return</span><span class="w"> </span>EXIT_WAIVED<span class="p">;</span>
</span><span id="__span-0-110">
</span><span id="__span-0-111"><span class="w">    </span>//<span class="w"> </span>申请内存
</span><span id="__span-0-112"><span class="w">    </span>const<span class="w"> </span>size_t<span class="w"> </span><span class="nv">buf_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1024</span><span class="w"> </span>*<span class="w"> </span><span class="m">1024</span><span class="w"> </span>*<span class="w"> </span><span class="m">16</span><span class="w"> </span>*<span class="w"> </span>sizeof<span class="o">(</span>float<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-113"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\tAllocating buffers %iMB\n&quot;</span>,<span class="w"> </span>int<span class="o">(</span>buf_size<span class="w"> </span>/<span class="w"> </span><span class="m">1024</span><span class="w"> </span>/<span class="w"> </span><span class="m">1024</span><span class="o">))</span><span class="p">;</span>
</span><span id="__span-0-114"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-115"><span class="w">    </span>float<span class="w"> </span>*g0<span class="p">;</span>
</span><span id="__span-0-116"><span class="w">    </span>cudaMalloc<span class="o">(</span><span class="p">&amp;</span>g0,<span class="w"> </span>buf_size<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-117"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-118"><span class="w">    </span>float<span class="w"> </span>*g1<span class="p">;</span>
</span><span id="__span-0-119"><span class="w">    </span>cudaMalloc<span class="o">(</span><span class="p">&amp;</span>g1,<span class="w"> </span>buf_size<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-120"><span class="w">    </span>float<span class="w"> </span>*h0<span class="p">;</span>
</span><span id="__span-0-121"><span class="w">    </span>cudaMallocHost<span class="o">(</span><span class="p">&amp;</span>h0,<span class="w"> </span>buf_size<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-122">
</span><span id="__span-0-123"><span class="w">    </span>cudaEvent_t<span class="w"> </span>start_event,<span class="w"> </span>stop_event<span class="p">;</span>
</span><span id="__span-0-124"><span class="w">    </span>int<span class="w"> </span><span class="nv">eventflags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>cudaEventBlockingSync<span class="p">;</span>
</span><span id="__span-0-125"><span class="w">    </span>float<span class="w"> </span>time_memcpy<span class="p">;</span>
</span><span id="__span-0-126"><span class="w">    </span>cudaEventCreateWithFlags<span class="o">(</span><span class="p">&amp;</span>start_event,<span class="w"> </span>eventflags<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-127"><span class="w">    </span>cudaEventCreateWithFlags<span class="o">(</span><span class="p">&amp;</span>stop_event,<span class="w"> </span>eventflags<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-128"><span class="w">    </span>cudaEventRecord<span class="o">(</span>start_event,<span class="w"> </span><span class="m">0</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-129">
</span><span id="__span-0-130"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="o">(</span>int<span class="w"> </span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;<span class="m">100</span><span class="p">;</span><span class="w"> </span>i++<span class="o">)</span>
</span><span id="__span-0-131"><span class="w">    </span><span class="o">{</span>
</span><span id="__span-0-132"><span class="w">        </span>//<span class="w"> </span>GPU<span class="w"> </span>互拷
</span><span id="__span-0-133"><span class="w">        </span>//<span class="w"> </span>UVA<span class="w"> </span>特性下<span class="w"> </span>cudaMemcpyDefault<span class="w"> </span>直接根据指针（属于主机还是设备）来确定拷贝方向
</span><span id="__span-0-134"><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>i<span class="w"> </span>%<span class="w"> </span><span class="nv">2</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="m">0</span><span class="o">)</span>
</span><span id="__span-0-135"><span class="w">            </span>cudaMemcpy<span class="o">(</span>g1,<span class="w"> </span>g0,<span class="w"> </span>buf_size,<span class="w"> </span>cudaMemcpyDefault<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-136"><span class="w">        </span><span class="k">else</span>
</span><span id="__span-0-137"><span class="w">            </span>cudaMemcpy<span class="o">(</span>g0,<span class="w"> </span>g1,<span class="w"> </span>buf_size,<span class="w"> </span>cudaMemcpyDefault<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-138"><span class="w">    </span><span class="o">}</span>
</span><span id="__span-0-139"><span class="w">    </span>cudaEventRecord<span class="o">(</span>stop_event,<span class="w"> </span><span class="m">0</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-140"><span class="w">    </span>cudaEventSynchronize<span class="o">(</span>stop_event<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-141"><span class="w">    </span>cudaEventElapsedTime<span class="o">(</span><span class="p">&amp;</span>time_memcpy,<span class="w"> </span>start_event,<span class="w"> </span>stop_event<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-142"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\tcudaMemcpy: %.2fGB/s\n&quot;</span>,<span class="w"> </span><span class="o">(</span><span class="m">100</span>.0f<span class="w"> </span>*<span class="w"> </span>buf_size<span class="o">)</span><span class="w"> </span>/<span class="w"> </span><span class="o">(</span><span class="m">1024</span>.0f<span class="w"> </span>*<span class="w"> </span><span class="m">1024</span>.0f<span class="w"> </span>*<span class="w"> </span><span class="m">1024</span>.0f<span class="w"> </span>*<span class="w"> </span><span class="o">(</span>time_memcpy<span class="w"> </span>/<span class="w"> </span><span class="m">1000</span>.0f<span class="o">)))</span><span class="p">;</span>
</span><span id="__span-0-143">
</span><span id="__span-0-144"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="o">(</span>int<span class="w"> </span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;buf_size<span class="w"> </span>/<span class="w"> </span>sizeof<span class="o">(</span>float<span class="o">)</span><span class="p">;</span><span class="w"> </span>i++<span class="o">)</span>
</span><span id="__span-0-145"><span class="w">        </span>h0<span class="o">[</span>i<span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>float<span class="o">(</span>i<span class="w"> </span>%<span class="w"> </span><span class="m">4096</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-146"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-147"><span class="w">    </span>cudaMemcpy<span class="o">(</span>g0,<span class="w"> </span>h0,<span class="w"> </span>buf_size,<span class="w"> </span>cudaMemcpyDefault<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-148">
</span><span id="__span-0-149"><span class="w">    </span>const<span class="w"> </span>dim3<span class="w"> </span>threads<span class="o">(</span><span class="m">512</span>,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-150"><span class="w">    </span>const<span class="w"> </span>dim3<span class="w"> </span>blocks<span class="o">((</span>buf_size<span class="w"> </span>/<span class="w"> </span>sizeof<span class="o">(</span>float<span class="o">))</span><span class="w"> </span>/<span class="w"> </span>threads.x,<span class="w"> </span><span class="m">1</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-151">
</span><span id="__span-0-152"><span class="w">    </span>//<span class="w"> </span>使用<span class="w"> </span>GPU1<span class="w"> </span>读取<span class="w"> </span>GPU0<span class="w"> </span>的全局内存数据，计算并写入<span class="w"> </span>GPU1<span class="w"> </span>的全局内存
</span><span id="__span-0-153"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\tRun kernel on GPU%d, reading data from GPU%d and writing to GPU%d\n&quot;</span>,<span class="w"> </span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">]</span>,<span class="w"> </span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">]</span>,<span class="w"> </span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-154"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-155"><span class="w">    </span>SimpleKernel<span class="o">&lt;&lt;&lt;</span>blocks,<span class="w"> </span>threads&gt;&gt;&gt;<span class="o">(</span>g0,<span class="w"> </span>g1<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-156"><span class="w">    </span>cudaDeviceSynchronize<span class="o">()</span><span class="p">;</span>
</span><span id="__span-0-157">
</span><span id="__span-0-158"><span class="w">    </span>//<span class="w"> </span>使用<span class="w"> </span>GPU0<span class="w"> </span>读取<span class="w"> </span>GPU1<span class="w"> </span>的全局内存数据，计算并写入<span class="w"> </span>GPU0<span class="w"> </span>的全局内存
</span><span id="__span-0-159"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\tRun kernel on GPU%d, reading data from GPU%d and writing to GPU%d\n&quot;</span>,<span class="w"> </span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">]</span>,<span class="w"> </span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">]</span>,<span class="w"> </span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-160"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-161"><span class="w">    </span>SimpleKernel<span class="o">&lt;&lt;&lt;</span>blocks,<span class="w"> </span>threads&gt;&gt;&gt;<span class="o">(</span>g1,<span class="w"> </span>g0<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-162"><span class="w">    </span>cudaDeviceSynchronize<span class="o">()</span><span class="p">;</span>
</span><span id="__span-0-163">
</span><span id="__span-0-164"><span class="w">    </span>//<span class="w"> </span>检查结果
</span><span id="__span-0-165"><span class="w">    </span>cudaMemcpy<span class="o">(</span>h0,<span class="w"> </span>g0,<span class="w"> </span>buf_size,<span class="w"> </span>cudaMemcpyDefault<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-166"><span class="w">    </span>int<span class="w"> </span><span class="nv">error_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">;</span>
</span><span id="__span-0-167"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="o">(</span>int<span class="w"> </span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;buf_size<span class="w"> </span>/<span class="w"> </span>sizeof<span class="o">(</span>float<span class="o">)</span><span class="p">;</span><span class="w"> </span>i++<span class="o">)</span>
</span><span id="__span-0-168"><span class="w">    </span><span class="o">{</span>
</span><span id="__span-0-169"><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>h0<span class="o">[</span>i<span class="o">]</span><span class="w"> </span>!<span class="o">=</span><span class="w"> </span>float<span class="o">(</span>i<span class="w"> </span>%<span class="w"> </span><span class="m">4096</span><span class="o">)</span><span class="w"> </span>*<span class="w"> </span><span class="m">2</span>.0f<span class="w"> </span>*<span class="w"> </span><span class="m">2</span>.0f<span class="o">)</span>
</span><span id="__span-0-170"><span class="w">        </span><span class="o">{</span>
</span><span id="__span-0-171"><span class="w">            </span>printf<span class="o">(</span><span class="s2">&quot;\n\tResult error at %i: gpu[i] = %f, cpu[i] = %f\n&quot;</span>,<span class="w"> </span>i,<span class="w"> </span>h0<span class="o">[</span>i<span class="o">]</span>,<span class="w"> </span><span class="o">(</span>float<span class="o">(</span>i%4096<span class="o">)</span>*2.0f*2.0f<span class="o">))</span><span class="p">;</span>
</span><span id="__span-0-172"><span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="o">(</span>error_count++<span class="w"> </span>&gt;<span class="w"> </span><span class="m">10</span><span class="o">)</span>
</span><span id="__span-0-173"><span class="w">                </span><span class="k">break</span><span class="p">;</span>
</span><span id="__span-0-174"><span class="w">        </span><span class="o">}</span>
</span><span id="__span-0-175"><span class="w">    </span><span class="o">}</span>
</span><span id="__span-0-176">
</span><span id="__span-0-177"><span class="w">    </span>//<span class="w"> </span>关闭<span class="w"> </span>P2P
</span><span id="__span-0-178"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-179"><span class="w">    </span>cudaDeviceDisablePeerAccess<span class="o">(</span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-180"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-181"><span class="w">    </span>cudaDeviceDisablePeerAccess<span class="o">(</span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-182">
</span><span id="__span-0-183"><span class="w">    </span>//<span class="w"> </span>回收工作
</span><span id="__span-0-184"><span class="w">    </span>cudaFreeHost<span class="o">(</span>h0<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-185"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">0</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-186"><span class="w">    </span>cudaFree<span class="o">(</span>g0<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-187"><span class="w">    </span>cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span><span class="m">1</span><span class="o">])</span><span class="p">;</span>
</span><span id="__span-0-188"><span class="w">    </span>cudaFree<span class="o">(</span>g1<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-189"><span class="w">    </span>cudaEventDestroy<span class="o">(</span>start_event<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-190"><span class="w">    </span>cudaEventDestroy<span class="o">(</span>stop_event<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-191"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="o">(</span>int<span class="w"> </span><span class="nv">i</span><span class="o">=</span><span class="m">0</span><span class="p">;</span><span class="w"> </span>i&lt;gpu_n<span class="p">;</span><span class="w"> </span>i++<span class="o">)</span>
</span><span id="__span-0-192"><span class="w">        </span>cudaSetDevice<span class="o">(</span>i<span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-193"><span class="w">    </span>printf<span class="o">(</span><span class="s2">&quot;\n\t%s!\n&quot;</span>,error_count?<span class="s2">&quot;Test failed&quot;</span>:<span class="w"> </span><span class="s2">&quot;Test passed&quot;</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-0-194">
</span><span id="__span-0-195"><span class="w">    </span>getchar<span class="o">()</span><span class="p">;</span>
</span><span id="__span-0-196"><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="m">0</span><span class="p">;</span>
</span><span id="__span-0-197"><span class="o">}</span>
</span></code></pre></div></td></tr></table></div>
<h3 id="2">2. 重要点<a class="headerlink" href="#2" title="Permanent link">&para;</a></h3>
<p>P2P 要求：至少两台计算能力不低于 2.0 的设备，并支持同一可视内存空间特性；计算环境不低于 CUDA 4.0；Windows 安装 Tesla 计算集群驱动。</p>
<h4 id="p2p">使用P2P的关键步骤<a class="headerlink" href="#p2p" title="Permanent link">&para;</a></h4>
<div class="language-bash highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Bash</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-1-1">//<span class="w"> </span>检查两台设备之间是否能使用<span class="w"> </span>P2P
</span><span id="__span-1-2">int<span class="w"> </span>can_access_peer<span class="p">;</span>
</span><span id="__span-1-3">cudaDeviceCanAccessPeer<span class="o">(</span><span class="p">&amp;</span>can_access_peer,<span class="w"> </span>gpuid<span class="o">[</span>i<span class="o">]</span>,<span class="w"> </span>gpuid<span class="o">[</span>j<span class="o">]))</span><span class="p">;</span>
</span><span id="__span-1-4">
</span><span id="__span-1-5">//<span class="w"> </span>启用<span class="w"> </span>P2P
</span><span id="__span-1-6">cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span>i<span class="o">])</span><span class="p">;</span>
</span><span id="__span-1-7">cudaDeviceEnablePeerAccess<span class="o">(</span>gpuid<span class="o">[</span>j<span class="o">]</span>,<span class="w"> </span><span class="m">0</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-1-8">cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span>j<span class="o">]</span><span class="p">;</span>
</span><span id="__span-1-9">cudaDeviceEnablePeerAccess<span class="o">(</span>gpuid<span class="o">[</span>i<span class="o">]</span>,<span class="w"> </span><span class="m">0</span><span class="o">)</span><span class="p">;</span>
</span><span id="__span-1-10">
</span><span id="__span-1-11">//<span class="w"> </span>设备间传输数据
</span><span id="__span-1-12">cudaMemcpy<span class="o">(</span>g1,<span class="w"> </span>g0,<span class="w"> </span>buf_size,<span class="w"> </span>cudaMemcpyDefault<span class="o">)</span><span class="p">;</span>
</span><span id="__span-1-13">
</span><span id="__span-1-14">//<span class="w"> </span>关闭<span class="w"> </span>P2P
</span><span id="__span-1-15">cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span>i<span class="o">])</span><span class="p">;</span>
</span><span id="__span-1-16">cudaDeviceDisablePeerAccess<span class="o">(</span>gpuid<span class="o">[</span>i<span class="o">])</span><span class="p">;</span>
</span><span id="__span-1-17">cudaSetDevice<span class="o">(</span>gpuid<span class="o">[</span>j<span class="o">])</span><span class="p">;</span>
</span><span id="__span-1-18">cudaDeviceDisablePeerAccess<span class="o">(</span>gpuid<span class="o">[</span>j<span class="o">])</span><span class="p">;</span>
</span><span id="__span-1-19">
</span><span id="__span-1-20">//<span class="w"> </span>cuda_runtime_api.h
</span><span id="__span-1-21">extern<span class="w"> </span>__host__<span class="w"> </span>cudaError_t<span class="w"> </span>CUDARTAPI<span class="w"> </span>cudaDeviceCanAccessPeer<span class="o">(</span>int<span class="w"> </span>*canAccessPeer,<span class="w"> </span>int<span class="w"> </span>device,<span class="w"> </span>int<span class="w"> </span>peerDevice<span class="o">)</span><span class="p">;</span>
</span><span id="__span-1-22">
</span><span id="__span-1-23">extern<span class="w"> </span>__host__<span class="w"> </span>cudaError_t<span class="w"> </span>CUDARTAPI<span class="w"> </span>cudaDeviceEnablePeerAccess<span class="o">(</span>int<span class="w"> </span>peerDevice,<span class="w"> </span>unsigned<span class="w"> </span>int<span class="w"> </span>flags<span class="o">)</span><span class="p">;</span>
</span><span id="__span-1-24">
</span><span id="__span-1-25">extern<span class="w"> </span>__host__<span class="w"> </span>cudaError_t<span class="w"> </span>CUDARTAPI<span class="w"> </span>cudaDeviceDisablePeerAccess<span class="o">(</span>int<span class="w"> </span>peerDevice<span class="o">)</span><span class="p">;</span>
</span></code></pre></div></td></tr></table></div>







  
  






                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 94c.cn
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/mvfeng/www_edit.git" target="_blank" rel="noopener" title="GitHub | mvfeng" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.top", "navigation.indexes", "navigation.expand", "search.suggest", "search.highlight", "content.code.copy", "content.action.edit"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.c8b220af.min.js"></script>
      
        <script src="../../mkdocs/javascripts/katex.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/katex.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.7/contrib/auto-render.min.js"></script>
      
        <script src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2832930496782786"></script>
      
    
  </body>
</html>